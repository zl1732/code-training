1. 选择排序
2. 冒泡排序


| 算法         | 时间复杂度           | 空间     | 稳定性   | 备注           |
| ----------- | ------------------ | ---------| ------- | ------------ |
| 冒泡 Bubble  | O(n²)              | O(1)     | ✅ 稳定  | 小学算法，了解即可    |
| 选择 Select  | O(n²)              | O(1)     | ❌ 不稳定 | 永远选择最小，容易跳位置 |
| 插入 Insert  | O(n²) / O(n)       | O(1)     | ✅ 稳定  | 局部有序/几乎有序时很快 |
| 希尔 Shell   | O(n^1.3 \~ n^1.6)  | O(1)     | ❌ 不稳定 | 插入排序的优化      |
| 快速 Quick   | O(n log n) / O(n²) | O(log n) | ❌ 不稳定 | 面试必会，快且原地    |
| 归并 Merge   | O(n log n)         | O(n)     | ✅ 稳定   | 面试必会，稳定但用空间  |
| 堆排 Heap    | O(n log n)         | O(1)     | ❌ 不稳定 | 建堆 + 每次取最大   |
| 桶排序 Bucket | O(n + k)\~O(n²)   | O(n + k) | ✅       | 适合均匀小数，非通用   |
| 基数排序 Radix | O(nk)             | O(n + k) | ✅      | 整数排序、定长字符串专用 |


| 会写代码 + 会讲原理         |
| ------------------- |
| ✅ 快排（重点）            |
| ✅ 归并（和快排互补）         |
| ✅ 堆排序（和 heap 结构一起学） |
| ✅ 插入排序（考细节/优化）      |


#### 1. 选择排序 ####
选择排序（朴素思维）：
    即每次都去遍历选择最小的元素
    先遍历一遍数组，找到数组中的最小值，然后把它和数组的第一个元素交换位置；
    接着再遍历一遍数组，找到第二小的元素，和数组的第二个元素交换位置；
    以此类推，直到整个数组有序。

特点:
    即便整个数组已经是有序的，它还是会执行 n^2 / 2 次，即原始数据的有序度对算法的时间复杂度没有任何影响。
    存在冗余计算

def sort(nums: List[int]) -> None:
    n = len(nums)
    # sortedIndex 是一个分割线
    # 索引 < sortedIndex 的元素都是已排序的
    # 索引 >= sortedIndex 的元素都是未排序的
    # 初始化为 0，表示整个数组都是未排序的
    sortedIndex = 0
    while sortedIndex < n:
        # 找到未排序部分 [sortedIndex, n) 中的最小值
        minIndex = sortedIndex
        for i in range(sortedIndex + 1, n):
            if nums[i] < nums[minIndex]:
                minIndex = i
        # 交换最小值和 sortedIndex 处的元素
        nums[sortedIndex], nums[minIndex] = nums[minIndex], nums[sortedIndex]

        # sortedIndex 后移一位
        sortedIndex += 1


思考：
    在遍历 nums[0..] 的时候，其实已经遍历过 nums[1..] 和 nums[2..] 的所有元素了
    如果能做到这一点，是不是就可以消掉内层的 for 循环，从把时间复杂度降低一个数量级？（不能！！）

    假设现在我知道了 nums[0..] 中的最小元素，我是否能够推导出 nums[1..] 中的最小元素呢？ ❌
    假设现在我知道了 nums[1..] 中的最小元素，我是否能够推导出 nums[0..] 中的最小元素呢？ ✅


    为什么不能：
        问题的关键在于交换操作。
        suffixMin 数组正确工作有个前提，就是 nums 数组不可变。
        如果 nums[i] 的值发生改变，那么所有 suffixMin[0..i] 存储的最小值就失效了，需要重新计算一次才行。



选择排序 不稳定：
    相同元素的相对位置不会发生变化才能称为稳定排序。你举个简单的例子就看出这个算法不稳定了：
    [2', 2''', 2'', 1]

    如果这个排序算法是稳定的，那么排序后的结果应该保持三个 2 的相对顺序：
    [1, 2', 2''', 2'']

    但实际上，第一次寻找最小值时，肯定会把元素 2' 和 1 交换，这一下就会打乱 2 之间的相对顺序了：
    [1, 2''', 2'', 2']  '


稳定：
    交换 vs 平移
    不要直接交换。而是将元素整体向后移动一位 把应该去的位置空出来让 nums[sortedIndex] 平移过去。

# 对选择排序进行第一波优化，获得了稳定性
def sort(nums):
    n = len(nums)
    sortedIndex = 0
    while sortedIndex < n:
        # 在未排序部分中找到最小值 nums[minIndex]
        minIndex = sortedIndex
        for i in range(sortedIndex + 1, n):
            if nums[i] < nums[minIndex]:
                minIndex = i

        # 优化：将 nums[minIndex] 插入到 nums[sortedIndex] 的位置
        # 将 nums[sortedIndex..minIndex] 的元素整体向后移动一位
        minVal = nums[minIndex]
        # 数组搬移数据的操作
        """
        这里又加了一个 for 循环，实际执行次数肯定会大于标准选择排序 
        能不能进一步优化，避免这个额外的 for 循环。
        """
        for i in range(minIndex, sortedIndex, -1):
            nums[i] = nums[i - 1]
        nums[sortedIndex] = minVal

        sortedIndex += 1




#### 2. 冒泡排序 ####
只交换相邻的逆序对儿，不会去碰值相同的元素，所以这个算法是稳定排序。

# 对选择排序进行第二波优化，获得稳定性的同时避免额外的 for 循环
def sort_list(nums):
    n = len(nums)
    sorted_index = 0
    while sorted_index < n:
        for i in range(n - 1, sorted_index, -1):
            if nums[i] < nums[i - 1]:
                # swap(nums[i], nums[i - 1])
                tmp = nums[i]
                nums[i] = nums[i - 1]
                nums[i - 1] = tmp
        sorted_index += 1


# 进一步优化，数组有序时提前终止算法
def sort(nums):
    n = len(nums)
    sorted_index = 0
    while sorted_index < n:
        # 加一个布尔变量，记录是否进行过交换操作
        swapped = False
        for i in range(n - 1, sorted_index, -1):
            if nums[i] < nums[i - 1]:
                # swap(nums[i], nums[i - 1])
                tmp = nums[i]
                nums[i] = nums[i - 1]
                nums[i - 1] = tmp
                swapped = True
        # 如果一次交换操作都没有进行，说明数组已经有序，可以提前终止算法
        if not swapped:
            break
        sorted_index += 1



#### 插入排序 ####
#### 插入排序 ####
#### 插入排序 ####
稳定，如同打扑克顺牌

进一步优化：
    上面的算法思路是：在 nums[sortedIndex..] 中找到最小值，然后将其插入到 nums[sortedIndex] 的位置。
    那么反过来想，在 nums[0..sortedIndex-1] 这个部分有序的数组中，找到 nums[sortedIndex] 应该插入的位置，然后进行插入
    既然 nums[0..sortedIndex-1] 这部分是已经排好序的，那么我就可以用二分搜索来寻找 nums[sortedIndex] 应该插入的位置。
    压缩到对数级别
    但是！
    就算我用二分搜索找到了 nums[sortedIndex] 应该插入的位置，我还是需要搬移元素进行插入，还是o（n）

初始有序度越高，效率越高：
    1. 如果输入数组已经有序，或者仅有个别元素逆序，那么插入排序的内层 for 循环几乎不需要执行元素交换，所以时间复杂度接近 O(n)。
    2. 如果输入的数组是完全逆序的，那么插入排序的效率就会很低，内层 for 循环每次都要对 nums[0..sortedIndex-1] 的所有元素进行交换，
        算法的总时间复杂度就接近 O(n^2)


# 对选择排序进一步优化，向左侧有序数组中插入元素
# 这个算法有另一个名字，叫做插入排序
def sort(nums):
    n = len(nums)
    # 维护 [0, sorted_index) 是有序数组
    sorted_index = 0
    while sorted_index < n:
        # 将 nums[sorted_index] 插入到有序数组 [0, sorted_index) 中
        for i in range(sorted_index, 0, -1):
            if nums[i] < nums[i - 1]:
                # swap(nums[i], nums[i - 1])
                tmp = nums[i]
                nums[i] = nums[i - 1]
                nums[i - 1] = tmp
            else:
                break
        sorted_index += 1
        """但从总体效率上，冒泡排序依然比不上插入排序，因为它每轮都要把元素一点点交换冒泡，而插入排序用的是“整体搬移 + 插入”，动作更高效。"""

对比:
    插入排序的综合性能应该要高于冒泡排序。
        数据搬移 vs 相邻交换
            插入排序是“整体搬移一段区间 + 插入一个元素”，代价是批量搬移，但整体效率较高。
            冒泡排序是“相邻元素两两交换”，代价是大量局部交换，次数更多。
        有序性利用率不同
            插入排序能利用“前缀已经有序”的性质 → 找到插入点后就停止。
            冒泡排序每轮都必须遍历到底，没法利用已有有序性。
    插排：
        插入排序的内层 for 循环，有序区间 → 可以提前终止，不必扫完。
        平均情况下，比较和移动次数 少于 O(n)，只在数组接近逆序时才达到最坏 O(n)。
        对几乎有序的数组，非常高效（接近 O(n)）。
    冒泡：
        内层循环每次必然走完整个区间，没法像插入排序那样“提前结束”。
        即使数组已经几乎有序，仍然会做很多不必要的比较。



#### 4. 希尔排序 ####
#### 4. 希尔排序 ####
#### 4. 希尔排序 ####
基于插入排序 的简单改进，通过预处理增加数组的局部有序性，突破了插入排序的 O(N^2)时间复杂度。
不稳定


间隔有序：
[1, 2, 4, 3, 5, 7, 8, 6, 10, 9, 12, 11]
 ^--------^--------^---------^
    ^--------^--------^---------^
       ^--------^--------^----------^

 1--------3--------8---------9
    2--------5--------6---------12
        4--------7--------10---------11

[1,3,8,9]、[2,5,6,12]、[4,7,10,11] 这三个数组都是有序的，间隔是 3。当一个数组完成排序的时候，其实就是 1 有序数组。

对比：为什么“分批整理”能让排序变快
    插入排序：
        直接把乱序数组变成 1 有序数组。
        如果数组接近 逆序，每个新元素都要往前挪很多步，移动距离最远可能是 O(n)。
    希尔排序：
        先把乱序数组变成一个 16 有序数组，然后再变成 8 有序数组，4 有序数组，2 有序数组，最后变成 1 有序数组，完成排序。
        希尔排序先设一个 gap，把数组分成若干子序列。
        在这些子序列里做插入排序。
        这样能让元素“快速跳跃”到更接近目标位置。

        总结：
        减少移动距离：
            元素通过“大步跳跃”更快接近它的最终位置。
        提前消除远距离逆序对：
            插入排序只能修复相邻逆序对。
            希尔排序先修复远距离逆序，再修复短距离逆序，整体工作量更少。

# 步长法
# 希尔排序，对 h 有序数组进行插入排序
# 逐渐缩小 h，最后 h=1 时，完成整个数组的排序
def sort(nums):
    n = len(nums)
    # 我们使用的生成函数是 2^(k-1)
    # 即 h = 1, 2, 4, 8, 16...
    h = 1
    while h < n // 2:
        h = 2 * h

    # 改动一，把插入排序的主要逻辑套在 h 的 while 循环中
    while h >= 1:
        # 改动二，sorted_index 初始化为 h，而不是 1
        sorted_index = h
        while sorted_index < n:
            # 改动三，把比较和交换元素的步长设置为 h，而不是相邻元素
            i = sorted_index
            while i >= h:
                if nums[i] < nums[i - h]:
                    # swap(nums[i], nums[i - h])
                    tmp = nums[i]
                    nums[i] = nums[i - h]
                    nums[i - h] = tmp
                else:
                    break
                i -= h
            sorted_index += 1

        # 按照递增函数的规则，缩小 h
        h //= 2

# 显式分组法
def shell_sort_group(nums):
    n = len(nums)
    h = n // 2  # 初始步长

    while h >= 1:
        # 把数组分成 h 个子序列：分别是 nums[0::h], nums[1::h], ..., nums[h-1::h]
        for start in range(h):
            # 对子序列做插入排序
            for i in range(start + h, n, h):
                key = nums[i]
                j = i - h
                # 插入排序的搬移逻辑
                while j >= 0 and nums[j] > key:
                    nums[j + h] = nums[j]
                    j -= h
                nums[j + h] = key
        # 缩小 gap
        h //= 2
    return nums



#### 5 快速排序 ####
1、在 nums 数组中任意选择一个元素作为切分元素 pivot（一般选择第一个元素）。

 [4, 1, 7, 2, 8, 5, 3, 6, 9]
  ^
pivot

2、将小于 pivot 的元素放到 pivot 的左边，大于 pivot 的元素放到 pivot 的右边。

 [3, 1, 2, 4, 8, 5, 7, 6, 9]
           ^
         pivot
         
3、递归地对 pivot 左边的数组和右边的数组重复上述步骤

 [3, 1, 2] [4] [8, 5, 7, 6, 9]
  ^         ^   ^
pivot1          pivot2

 [1, 2, 3] [4] [5, 7, 6, 8, 9]
        ^   ^            ^
    pivot1             pivot2




        [4, 1, 7, 2, 5, 3, 6]
         /                 \
    [2, 1, 3]    [4]     [7, 5, 6]
     /     \              /     \
  [1]  [2]  [3]        [5]  [6]  [7]

每一层的数组元素总数都大致是数组长度 O(n)。


理想情况这棵树是平衡二叉树，即树高是 O(logn)，所以总的时间复杂度是 
O(nlogn)
不需要额外的辅助空间，是原地排序算法。
递归遍历二叉树时，递归函数的堆栈深度为树的高度，所以空间复杂度是 
O(logn)

def sort(nums: List[int], lo: int, hi: int):
    if lo >= hi:
        return
    # ****** 前序位置 ******
    # 对 nums[lo..hi] 进行切分，将 nums[p] 排好序
    # 使得 nums[lo..p-1] <= nums[p] < nums[p+1..hi]
    p = partition(nums, lo, hi)

    # 去左右子数组进行切分
    sort(nums, lo, p - 1)
    sort(nums, p + 1, hi)


def partition(nums: List[int], lo: int, hi: int) -> int:
    pivot = nums[hi]  # 选择最后一个元素作为基准
    i = lo  # i 指向小于等于 pivot 的区域的边界

    for j in range(lo, hi):
        if nums[j] <= pivot:
            nums[i], nums[j] = nums[j], nums[i]
            i += 1
    # 把 pivot 放到最终位置
    nums[i], nums[hi] = nums[hi], nums[i]
    return i


Lomuto版本：
每次循环只动一边的指针。
缺点：当数据很多重复值时，左边会偏大，可能导致退化。

🔑 核心变量
    j：扫描指针，从左往右一个个检查元素。
    i：边界指针，指向「下一个 ≤ pivot 元素应该放的位置」。
    
    左边 [lo..i-1]：都 ≤ pivot
    中间 i：最后放 pivot
    右边 [i+1..hi]：都 > pivot

✅ 总结
    j 一直往右扫，看每个数是否 ≤ pivot。
    如果 nums[j] <= pivot，就把它放到左边（即换到 i 位置），然后 i++。
    最后把 pivot 放到 i，就完成分区。

# hoare方法
def quicksort(nums, lo, hi):
    if lo < hi:
        # 用 Hoare 方法分区
        p = partition_hoare(nums, lo, hi)
        # 注意：递归的时候要用 [lo..p] 和 [p+1..hi]
        quicksort(nums, lo, p)
        quicksort(nums, p + 1, hi)
def partition(nums: List[int], lo: int, hi: int) -> int:
    # 选择第一个元素作为 pivot
    pivot = nums[lo]
    i, j = lo + 1, hi

    while i <= j:
        # i 向右走，直到遇到一个 > pivot 的数
        while i < hi and nums[i] <= pivot:
            i += 1
        # j 向左走，直到遇到一个 <= pivot 的数
        while j > lo and nums[j] > pivot:
            j -= 1
        # 两边指针相遇，退出
        if i >= j:
            break
        # 交换不在位置的元素
        nums[i], nums[j] = nums[j], nums[i]

    # 把 pivot 放到正确位置
    nums[lo], nums[j] = nums[j], nums[lo]
    return j


def partition_hoare(nums, lo, hi):
    pivot = nums[lo]
    i, j = lo - 1, hi + 1
    while True:
        i += 1
        while nums[i] < pivot:
            i += 1
        j -= 1
        while nums[j] > pivot:
            j -= 1
        if i >= j:
            return j
        nums[i], nums[j] = nums[j], nums[i]


#### 6.归并排序 ####
#### 6.归并排序 ####
#### 6.归并排序 ####
把数组切成两半，先把这两半子数组分别排好序，然后再合并这两个有序数组，整个数组就排好序了。
归并排序是稳定排序。
归并排序的 merge 函数需要一个额外的数组来辅助进行有序数组的合并操作，消耗 
O(n) 的空间。

# 定义：排序 nums[lo..hi]
def sort(nums: List[int], lo: int, hi: int) -> None:
    if lo == hi:
        return
    mid = (lo + hi) // 2
    # 利用定义，排序 nums[lo..mid]
    sort(nums, lo, mid)
    # 利用定义，排序 nums[mid+1..hi]
    sort(nums, mid + 1, hi)

    # ****** 后序位置 ******
    # 此时两部分子数组已经被排好序
    # 合并两个有序数组，使 nums[lo..hi] 有序
    merge(nums, lo, mid, hi)

def merge(nums: List[int], lo: int, mid: int, hi: int) -> None:
    # 创建临时数组
    temp = []
    i, j = lo, mid + 1

    # 合并两个有序子数组
    while i <= mid and j <= hi:
        if nums[i] <= nums[j]:
            temp.append(nums[i])
            i += 1
        else:
            temp.append(nums[j])
            j += 1

    # 把剩下的元素补上
    while i <= mid:
        temp.append(nums[i])
        i += 1
    while j <= hi:
        temp.append(nums[j])
        j += 1

    # 回写到原数组
    nums[lo:hi + 1] = temp


# 测试
nums = [5, 2, 3, 1, 4]
sort(nums, 0, len(nums) - 1)
print(nums)  # [1, 2, 3, 4, 5]


 
#### 7 二叉堆结构的运用：堆排序 ####
堆排序（以升序排序为例，用大顶堆）
建堆
    目标：把无序数组变成一个大顶堆（最大值在堆顶）。
    方法有两种：
        swim 上浮建堆：从头到尾扫描数组，每插入一个新元素，就向上“冒泡”调整位置，保持堆序。复杂度 O(n log n)。
        sink 下沉建堆（推荐）：从最后一个非叶子节点开始，逐个向下调整。复杂度 O(n)。
排序
    现在堆顶是整个数组最大值，把它和最后一个元素交换。
    把堆的有效范围缩小一格（相当于“去掉最后一个元素”，它已经是最大值，放在正确位置了）。
    对新的堆顶进行 sink 下沉，让堆重新满足大顶堆性质。
    重复上面步骤，直到堆只剩一个元素。

建堆 → 不断交换堆顶与末尾 → 缩小堆范围 → 下沉堆顶 → 直到排完
def min_heap_swim(heap, node):
    # 小顶堆的上浮操作，时间复杂度是树高 O(logN)
    while node > 0 and heap[parent(node)] > heap[node]:
        swap(heap, parent(node), node)
        node = parent(node)


def min_heap_sink(heap, node, size):
    # 小顶堆的下沉操作，时间复杂度是树高 O(logN)
    while left(node) < size or right(node) < size:
        # 比较自己和左右子节点，看看谁最小
        min_index = node
        if left(node) < size and heap[left(node)] < heap[min_index]:
            min_index = left(node)
        if right(node) < size and heap[right(node)] < heap[min_index]:
            min_index = right(node)
        if min_index == node:
            break
        # 如果左右子节点中有比自己小的，就交换
        swap(heap, node, min_index)
        node = min_index


def max_heap_swim(heap, node):
    # 大顶堆的上浮操作
    while node > 0 and heap[parent(node)] < heap[node]:
        swap(heap, parent(node), node)
        node = parent(node)


def max_heap_sink(heap, node, size):
    # 大顶堆的下沉操作
    while left(node) < size or right(node) < size:
        # 小顶堆和大顶堆的唯一区别就在这里，比较逻辑相反
        # 比较自己和左右子节点，看看谁最大
        max_index = node
        if left(node) < size and heap[left(node)] > heap[max_index]:
            max_index = left(node)
        if right(node) < size and heap[right(node)] > heap[max_index]:
            max_index = right(node)
        if max_index == node:
            break
        swap(heap, node, max_index)
        node = max_index


def parent(node):
    # 父节点的索引
    return (node - 1) // 2


def left(node):
    # 左子节点的索引
    return node * 2 + 1


def right(node):
    # 右子节点的索引
    return node * 2 + 2


def swap(heap, i, j):
    # 交换数组中两个元素的位置
    heap[i], heap[j] = heap[j], heap[i]


def sort(nums):
    # 第一步，原地建堆，注意这里创建的是大顶堆
    # 只要从左往右对每个元素调用 swim 方法，就可以原地建堆
    for i in range(len(nums)):
        max_heap_swim(nums, i)

    # 第二步，排序
    # 现在整个数组已经是一个大顶了，直接模拟删除堆顶元素的过程即可
    heap_size = len(nums)
    while heap_size > 0:
        # 从堆顶删除元素，放到堆的后面
        swap(nums, 0, heap_size - 1)
        heap_size -= 1
        # 恢复堆的性质
        max_heap_sink(nums, 0, heap_size)
        # 现在 nums[0..heap_size) 是一个大顶堆，nums[heap_size..) 是有序元素

"""优化
每个点由上至下swim
变成
每个非叶子节点 由下至上 sink
因为
sink好的左右子堆，只要把父节点sink，就可以保证整个都是堆


前序 → swim：先根后子
插入时你是从根到叶“开路径”，每个新点一边走一边调整。

后序 → sink：先子后根
建堆时你先保证每棵子树是堆，再调整它们的根节点。

换句话说：
swim 是 自顶向下修正路径，sink 是 自底向上构建结构。

4. 什么时候用哪种？
数据是流式到来的 → swim（优先级队列）
数据一次性给全 → sink（堆排序、heapify）  sink 是 O(n) 数学推导的不用管
"""

def sort(nums):
    # 第一步，原地建堆，注意这里创建的是大顶堆
    # 从最后一个非叶子节点开始，依次下沉，合并二叉堆
    n = len(nums)
    for i in range(n // 2 - 1, -1, -1):
        max_heap_sink(nums, i, n)

    # 合并完成，现在整个数组已经是一个大顶堆

    # 第二步，排序，和刚才的代码一样
    heap_size = n
    while heap_size > 0:
        # 从堆顶删除元素，放到堆的后面
        swap(nums, 0, heap_size - 1)
        heap_size -= 1
        # 恢复堆的性质
        max_heap_sink(nums, 0, heap_size)
        # 现在 nums[0..heap_size) 是一个大顶堆，nums[heap_size..) 是有序元素
"""
# 直接利用优先级队列对数组从小到大排序
def sort(nums):
    # 创建一个从小到大排序元素的小顶堆
    pq = SimpleMinPQ(len(nums))
    
    # 先把所有元素插入到优先级队列中
    for num in nums:
        # push 操作会自动构建二叉堆，时间复杂度为 O(logN)
        pq.push(num)
    
    # 再把所有元素取出来，就是从小到大排序的结果
    for i in range(len(nums)):
        # pop 操作从堆顶弹出二叉堆堆中最小的元素，时间复杂度为 O(logN)
        nums[i] = pq.pop() 

注意：
    push和pop已经包含上浮交换等操作
    # 增，向堆中插入一个元素，时间复杂度 O(logN)
    def push(self, x):
        # 把新元素追加到最后
        self.heap[self.size] = x
        # 然后上浮到正确位置
        self.swim(self.size)
        self.size += 1

    # 删，删除堆顶元素，时间复杂度 O(logN)
    def pop(self):
        res = self.heap[0]
        # 把堆底元素放到堆顶
        self.heap[0] = self.heap[self.size - 1]
        self.size -= 1
        # 然后下沉到正确位置
        self.sink(0)
        return res       
"""

先保证子树是堆，再 sink 根节点 → 整棵树堆序成立。



## 计数排序
def counting_sort_with_negatives(nums):
    if not nums:
        return nums

    min_val = min(nums)
    max_val = max(nums)

    # 偏移量：将所有值映射为非负整数
    offset = -min_val
    count_size = max_val - min_val + 1

    # 1. 创建并填充计数数组
    count = [0] * count_size
    for num in nums:
        count[num + offset] += 1

    # 2. 构建前缀和，表示 <= i 的元素有多少个
    for i in range(1, count_size):
        count[i] += count[i - 1]

    # 3. 构建输出数组（倒序保证稳定）
    output = [0] * len(nums)
    for num in reversed(nums):
    #for i in range(len(nums) - 1, -1, -1):
        idx = num + offset
        output[count[idx]] = num
        count[idx] -= 1
    return output



def counting_sort_numeric(nums):
    if not nums:
        return nums
    mn, mx = min(nums), max(nums)
    off = -mn
    count = [0] * (mx - mn + 1)

    for x in nums:
        count[x + off] += 1

    # 前缀和
    for i in range(1, len(count)):
        count[i] += count[i - 1]

    out = [0] * len(nums)
    for x in reversed(nums):           # 倒序保证稳定
        idx = x + off
        count[idx] -= 1
        out[count[idx]] = x
    return out




# 桶排序
"""
桶排序（Bucket Sort）笔记总结

🧱 一、算法分为三个阶段：

1. 分桶（分发阶段） O(n)
   - 将输入数据根据映射函数分发到 k 个桶中
   - 常用映射： index = int(x * k)（适用于 [0, 1) 区间的浮点数）
    错误：int bucketIndex = nums[i] % k;因为合并有序桶的时间复杂度就会超过 O(n)。


2. 桶内排序        O(n²/k)（取决于桶内排序方式）
   - 每个桶内部用插入排序 / 快排 / Timsort 等方法进行排序
   - 如果元素分布均匀，每个桶约有 n/k 个元素
   - 插入排序下每个桶排序时间为 O((n/k)^2)，共 k 个桶，总体为 O(n²/k)
   - 快排下总桶内排序复杂度为 O(n log(n/k))

3. 拼接桶（合并阶段） O(n)
    桶 0: [0.0, 0.2)
    桶 1: [0.2, 0.4)
    桶 2: [0.4, 0.6)
    桶 3: [0.6, 0.8)
    桶 4: [0.8, 1.0)
   - 顺序遍历每个桶，将桶中已排好序的元素按顺序复制或拼接到结果数组
   - 由于桶编号天然有序，直接拼接即可，无需比较或归并

🧮 二、时间复杂度汇总：

设：
- n 为元素总数
- k 为桶的数量
- m = n/k 为每个桶的平均元素个数

则总复杂度为：

🔸 最坏情况（所有元素落入一个桶）：O(n²)
🔸 最佳情况（均匀分布 + 每桶 ≤ 常数个元素）：O(n)
🔸 一般情况：
    • 插入排序： O(n² / k + n)
    • 快速排序： O(n log(n/k) + n)

⚠️ 注意：
- 分桶与拼接都是线性复杂度 O(n)，不是主要瓶颈
- 桶内排序方式与元素分布决定了整体性能
- 桶排序适用于输入数据分布较均匀、值域已知的场景（如 [0, 1) 浮点数）

"""

### 1. 插排
def insertion_sort(arr):
    for i in range(1, len(arr)):
        key = arr[i]
        j = i - 1
        while j >= 0 and arr[j] > key:
            arr[j + 1] = arr[j]
            j -= 1
        arr[j + 1] = key


def bucket_sort(nums, bucket_count=10):
    if not nums:
        return []
    min_val = min(nums)
    max_val = max(nums)
    ε = 1e-9  # 避免除以 0
    
    buckets = [[] for _ in range(bucket_count)]
    for num in nums:
        index = int((num - min_val) / (max_val - min_val + ε) * bucket_count) # 归一化
        index = min(index, bucket_count - 1)  # 防止越界
        buckets[index].append(num)

    for bucket in buckets:
        insertion_sort(bucket)

    # 4️⃣ 拼接阶段：按桶编号顺序合并所有桶
    sorted_nums = []
    for bucket in buckets:
        sorted_nums.extend(bucket)

    return sorted_nums


#



def is_sorted(arr):
    """判断一个数组是否已经升序"""
    return all(arr[i] <= arr[i + 1] for i in range(len(arr) - 1))


def bucket_sort(nums, bucket_count=10):
    """
    递归版桶排序：适用于任意实数范围，桶内继续使用桶排序（递归），直到有序或规模很小

    🧠 举例说明 base case #2 的必要性：
    假设你有个数组：
    nums = [0.1, 0.1, 0.1, 0.1]
    这些数全都落到一个桶里
    再递归这个桶时，min == max，会导致归一化时所有值仍映射到 index 0
    如果你没有 is_sorted check，你就会无限递归地对 [0.1, 0.1, 0.1, 0.1] 调用自己！☠️
    有了 is_sorted，直接触发 base case，递归返回 ✅

    Base 3: 近似比较，避免[1,1+1e-9]这种卡无限循环
        >>> a = 0.1 + 0.2
        >>> b = 0.3
        >>> print(a == b)
        False
    因为
        0.1 + 0.2 = 0.30000000000000004
              0.3 = 0.3000000000000000
    Python 官方推荐怎么比较浮点数？
        Python 提供了一个官方函数：math.isclose()
        math.isclose(a, b, rel_tol=1e-9, abs_tol=0.0)
    """
    # base 1
    if len(nums) <= 1:
        return nums[:]
    # base 2
    if is_sorted(nums):
        return nums[:]

    min_val = min(nums)
    max_val = max(nums)
    ε = 1e-9

    # base 3
    if abs(max_val - min_val) < ε:
        return nums[:]

    # 初始化桶
    buckets = [[] for _ in range(bucket_count)]

    # 分发元素
    for num in nums:
        index = int((num - min_val) / (max_val - min_val + ε) * bucket_count)
        index = min(index, bucket_count - 1)
        buckets[index].append(num)

    # 递归对每个桶排序
    sorted_nums = []
    for bucket in buckets:
        if len(bucket) <= 1:
            sorted_nums.extend(bucket)
        else:
            # 递归调用自己
            sorted_bucket = bucket_sort(bucket, bucket_count)
            sorted_nums.extend(sorted_bucket)

    return sorted_nums


"""
稳定性：
    排序稳定性主要取决于对每个桶的排序算法。
    1. 插入排序，稳定
    2. 选择排序，不稳定
    3. 遍历方法，稳定


✅ 一、空间复杂度 = O(n + k)
📦 有两个来源：

n 是元素总数

你要把所有元素分发进桶 ⇒ 总共 n 个数要被复制（虽然有可能是引用）

k 是桶的数量

即使有的桶是空的，你仍然开了 k 个桶（通常是 k ≈ √n 或固定值）


✅ 二、均摊时间复杂度 = O(n + k)

这是桶排序最“理想情况”的时间复杂度 —— 所谓的“均摊分析”。
🧠 理想前提：

元素分布 均匀随机，每个桶里大致只有常数个元素
并且桶内排序算法是 O(m²) 的（比如插排），但 m 很小

📈 三个阶段时间分析：
| 阶段   | 操作             | 时间复杂度                                 |
| ---- | -------------- | ------------------------------------- |
| 分发   | 把每个元素放进对应桶     | O(n)                                  |
| 桶内排序 | k 个桶，每个桶 m 个元素 | k × O(m²) = O(n²/k) ⇒ 当 m ≈ 常数 ⇒ O(n) |
| 拼接   | 遍历所有桶把元素合并     | O(n)                                  |


选对 k ⇒ 优化复杂度：
如果你设定 k ≈ n（每个桶 1 个元素）：
O(n² / k) = O(n² / n) = O(n)
所以只要 分布合理 + 桶足够多，就可以获得：
✅ 均摊时间复杂度：O(n + k)（常常简写为 O(n)）
"""
